# From $0$ to $i$

## 1, 2, 3, ...

What do these 4 scenarios have in common?

![4 scenarios containing a single object](./analogies-1.png)

Each contains 1 object.
Turning this around, we can _define_ 1 as the quality they have in common.
Likewise, we can define 2 as the common quality in the following 4 scenarios:

![4 scenarios containing two objects](./analogies-2.png)

We can define 3 in the same way:

![4 scenarios containing three objects](./analogies-3.png)

And likewise with 4, 5, 6, ...

So our first experience with numbers is as analogies.
We can develop some basic notions of order (the "2-situations" all contain
"1-situations" inside them, but not vice-versa).
We can also define addition as a combining operation, and multiplication as
"bulk replacement".
Finally, we might recognize the "nothing situation" which contains _no_ objects;
we've discovered 0.

## Natural numbers

In treating numbers as analogies, we find that we can always add another number
to our collection.
We also have a smallest number: 0.
These two properties define the natural numbers, $\mathbb{N}$:

$$
\begin{align*}
0 &\in \mathbb{N} \\
n \in \mathbb{N} \implies \mathrm{suc}(n) &\in \mathbb{N}
\end{align*}
$$

That is, there's some natural number called $0$, and given any natural number
$n$, there's another natural number $\mathrm{suc}(n)$.
We can use these to recursively build up the first few natural numbers:

$$
\begin{align*}
0 &\in \mathbb{N} \\
\mathrm{suc}(0) &\in \mathbb{N} \\
\mathrm{suc}(\mathrm{suc}(0)) &\in \mathbb{N} \\
\mathrm{suc}(\mathrm{suc}(\mathrm{suc}(0))) &\in \mathbb{N} \\
&\cdots
\end{align*}
$$

We can define addition by:

$$
\begin{align*}
0 + n &= n \\
\mathrm{suc}(m) + n &= \mathrm{suc}(m + n)
\end{align*}
$$

This definition looks circular, but it's not: if the first number is $0$, it
produces an answer; otherwise it reduces to a _smaller_ addition problem.
Here's $2 + 3$:

$$
\begin{align*}
\mathrm{suc}(\mathrm{suc}(0)) + \mathrm{suc}(\mathrm{suc}(\mathrm{suc}(0))) &=
   \mathrm{suc}(\mathrm{suc}(0) + \mathrm{suc}(\mathrm{suc}(\mathrm{suc}(0)))) \\
&= \mathrm{suc}(\mathrm{suc}(0 + \mathrm{suc}(\mathrm{suc}(\mathrm{suc}(0))))) \\
&= \mathrm{suc}(\mathrm{suc}(\mathrm{suc}(\mathrm{suc}(\mathrm{suc}(0)))))
\end{align*}
$$

We can define multiplication in a similar fashion:

$$
\begin{align*}
0 \cdot n &= 0 \\
\mathrm{suc}(m) \cdot n &= n + (m \cdot n)
\end{align*}
$$

We can _prove_ that addition is associative:

$$
\begin{align*}
(0 + b) + c &= b + c \\
            &= 0 + (b + c) \\
(\mathrm{suc}(a) + b) + c &= \mathrm{suc}(a + b) + c \\
                          &= \mathrm{suc}((a + b) + c) \\
                          &= \mathrm{suc}(a + (b + c)) &\textrm{[Induction hypothesis]} \\
                          &= \mathrm{suc}(a) + (b + c)
\end{align*}
$$

$\mathbb{N}$ is a "commutative monoid" under both addition and multiplication.
This means that both addition and multiplication are associative, commutative,
and have an identity.
We can prove all of these facts.
Why is $\mathbb{N}$ _not_ a commutative monoid under exponentiation?

## Integers

The integers are an extension of the natural numbers, in both an informal and
technical sense.
We begin by defining the set $\mathrm{Z} = \mathbb{N} \times \mathbb{N}$.
That is, $\mathrm{Z}$ is the set of pairs of natural numbers.
We think of the elements of $\mathrm{Z}$, say $(a, b)$ as representing the
_difference_ $a - b$.
This allows us to represent negative numbers.

When defining $\mathbb{N}$ there was only one way to represent each number.
Now there are many ways (an infinite amount) to represent the same number.
We capture this idea with an equivalence relation:

$$
(a, b) \sim (c, d) \Longleftrightarrow a + d = b + c
$$

So $(1, 3) \sim (2, 4)$ and $(5, 4) \sim (1, 0)$.

*TODO* Prove that this is an equivalence.

We can now define $\mathbb{Z}$ as the set of equivalence classes of $\mathrm{Z}$
with respect to $\sim$:

$$
\mathbb{Z} = \mathrm{Z} \thinspace / \sim
$$

We can define addition on $\mathrm{Z}$ by

$$
(a, b) + (c, d) = (a + c, b + d)
$$

Can we use this to define addition on $\mathbb{Z}$?
Yes and no.
The elements of $\mathbb{Z}$ are entire equivalence classes (subsets) of
$\mathrm{Z}$.
In this cases, we could select some "canonical representative" of each
equivalence class, which would allow us to define addition on $\mathbb{Z}$, but
we won't always be able to do this.
Instead, we're actually accustomed to operating on numbers _via their names_.

All that we need to show is that $+$ _respects_ the equivalence relation $\sim$.
This means that

$$
x \sim x', y \sim y' \implies x + y \sim x' + y'
$$

This just says that regardless of which elements of two equivalence classes we
choose, their sum is in the same equivalence class.

The integers were motivated by a desire to have additive inverses.
Let's define negation:

$$
\mathrm{neg}(a, b) = (b, a)
$$

Negation is always well-defined.
Subtraction is defined in terms of negation:

$$
x - y = x + \mathrm{neg}(y)
$$

The integers form a ring.
*TODO* Prove all of this.

Note that any natural number can be "promoted" to an integer by pairing it with $0$:

$$
\mathrm{promote}(n) = (n, 0)
$$

## Rational numbers

The construction of the rationals will look familiar.
We begin by defining a set

$$
\mathrm{Q} = \left\{ (x, y) \in \mathbb{Z} \times \mathbb{Z} \mid y \neq 0 \right\}
$$

That is, $\mathrm{Q}$ is the set of pairs of integers, where the second element
isn't $0$.
Here we're thinking of each pair $(x, y)$ as the _quotient_ $\frac{x}{y}$.
We define an equivalence relation $\sim$ by

$$
(x, y) \sim (z, w) \Longleftrightarrow xw = yz
$$

We define addition on $\mathrm{Q}$:

$$
(x, y) + (z, w) = (xw + yz, yw)
$$

We need to prove a few things about $+$:

1. The result is actually in $\mathrm{Q}$
2. It respects $\sim$.

Each integer can be promoted to a rational by pairing it with $1$:

$$
\mathrm{promote}(z) = (z, 1)
$$

## Real numbers

The ratio of the length of the diagonal of a square to its side is not
expressible as a rational number.
Yet both of these lengths are finite, and fairly similar in length.
It feels like this ratio _ought_ to be expressible as a number.

This should look familiar by now.
Define

$$
\mathrm{R} = \left\{ \sigma \in \mathbb{N} \to \mathbb{Q} \mid \sigma \textrm{ is Cauchy} \right\}
$$

A sequence $\sigma$ is "Cauchy" if its terms get arbitrarily close to each other
at some point.
Specifically, iff

$$
\forall B \in \mathbb{N}, \exists N \in \mathbb{N} : m, n \geq N \implies |\sigma(m) - \sigma(n)| < \frac{1}{B}
$$

Define $\sim$ by

$$
\sigma \sim \tau \Longleftrightarrow (\sigma - \tau) \to 0
$$

where we've introduced a new idea: $\to 0$.
A sequence $\sigma$ _converges to $0$_ iff

$$
\forall B \in \mathbb{N}, \exists N \in \mathbb{N} : n \geq N \implies |\sigma(n)| < \frac{1}{B}
$$

To recap: we've defined a new set $\mathrm{R}$ as the set of Cauchy sequences of
rational numbers, and said that two elements of $\mathrm{R}$ are equivalent if
their difference converges to $0$.

Then

$$
\mathbb{R} = \mathrm{R} \thinspace / \sim
$$

$\mathbb{R}$ is _Cauchy complete_: every Cauchy sequence in $\mathbb{R}$ has a
limit.

## Complex numbers

Perhaps surprisingly, the complex numbers are _easier_ to define:

$$
\mathbb{C} = \mathbb{R} \times \mathbb{R}
$$

The complex numbers are algebraicly complete.
